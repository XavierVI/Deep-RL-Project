{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "47f5e5d2",
   "metadata": {},
   "source": [
    "This notebook is used to preprocess the CocoDoom dataset to allow for faster training.\n",
    "\n",
    "Each image will be loaded, preprocessed, and saved as a tensor shard in the same location as the original images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "15647086",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xavier/python-venvs/doom-venv/lib64/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Add project directory to path for imports\n",
    "from transformers import DetrImageProcessorFast\n",
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.join(os.pardir))\n",
    "\n",
    "from PIL import Image\n",
    "from Vision.datasets import CocoDoomDataset\n",
    "from transformers import DetrImageProcessor\n",
    "\n",
    "import torch\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "28a54d84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.93s)\n",
      "creating index...\n",
      "index created!\n",
      "loading annotations into memory...\n",
      "Done (t=0.92s)\n",
      "creating index...\n",
      "index created!\n",
      "Loaded run-train.json\n",
      "Number of images: 50732\n",
      "Number of Categories: 94\n"
     ]
    }
   ],
   "source": [
    "# create preprocessor\n",
    "processor = DetrImageProcessor.from_pretrained(\n",
    "    \"facebook/detr-resnet-50\",\n",
    "    size={\"shortest_edge\": 200, \"longest_edge\": 320}\n",
    ")\n",
    "\n",
    "# create dataset instance\n",
    "dataset = CocoDoomDataset(\n",
    "    data_dir=os.path.join(os.pardir, os.pardir, \"datasets\", \"cocodoom\"),\n",
    "    annotation_file_name=\"run-train.json\",\n",
    "    processor=processor\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "73f7fe12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cache X GB of data\n",
    "from tqdm import tqdm\n",
    "\n",
    "def cache_files():\n",
    "    split_name = \"train\"\n",
    "    saved, skipped = 0, 0\n",
    "    save_root = os.path.join(\n",
    "        os.pardir, os.pardir, \"datasets\", \"cocodoom\", \"preprocessed\"\n",
    "    )\n",
    "    os.makedirs(save_root, exist_ok=True)\n",
    "\n",
    "    cache_size_gb = 64\n",
    "    # use uniform distribution to sample what idx should be cached\n",
    "    dist = torch.distributions.Uniform(0, len(dataset))\n",
    "    approx_item_size = 0.012 # in GB\n",
    "    num_items_to_cache = int(cache_size_gb / approx_item_size)\n",
    "    print(f\"Caching approximately {num_items_to_cache} items (~{cache_size_gb} GB)\")\n",
    "    sampled_indices = dist.sample((num_items_to_cache,)).long().tolist()\n",
    "\n",
    "\n",
    "    for i in tqdm(sampled_indices, desc=f\"Preprocessing {split_name}\"):\n",
    "        image, target, img_file_name = dataset.get_image(i)\n",
    "\n",
    "        encoding = processor(\n",
    "            images=image,\n",
    "            annotations=target,\n",
    "            return_tensors=\"pt\"\n",
    "        )\n",
    "\n",
    "        pixel_values = encoding['pixel_values'].squeeze()\n",
    "        target = dict(encoding['labels'][0])\n",
    "\n",
    "        # reduce format of target tensors\n",
    "        # target['boxes'] = target['boxes'].to(torch.float16)\n",
    "        # del target['size']\n",
    "        # del target['orig_size']\n",
    "        # # we only have 94 categories\n",
    "        # target['class_labels'] = target['class_labels'].to(torch.int16)\n",
    "        # del target['area']  # remove area to save space\n",
    "        # del target['iscrowd'] # remove iscrowd to save space\n",
    "\n",
    "        # modify file name to have .pt extension\n",
    "        # pt_file_name = os.path.splitext(img_file_name)[0] + \".pt\"\n",
    "        pt_file_name = f\"{i}.pt\"\n",
    "        save_path = os.path.join(save_root, pt_file_name)\n",
    "\n",
    "        if not os.path.exists(os.path.dirname(save_path)):\n",
    "            os.makedirs(os.path.dirname(save_path), exist_ok=True)\n",
    "\n",
    "        if os.path.exists(save_path):\n",
    "            skipped += 1\n",
    "            continue\n",
    "\n",
    "        torch.save(\n",
    "            {\n",
    "                \"pixel_values\": pixel_values,\n",
    "                \"labels\": target\n",
    "            },\n",
    "            save_path\n",
    "        )\n",
    "        saved += 1\n",
    "\n",
    "    print(f\"{split_name}: saved {saved}, skipped {skipped}\")\n",
    "\n",
    "# cache_files()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "894ef904",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pixel values shape: torch.Size([3, 200, 320])\n",
      "Loaded labels: {'size': tensor([200, 320]), 'image_id': tensor([1010000002]), 'class_labels': tensor([0, 0]), 'boxes': tensor([[0.4328, 0.6225, 0.0531, 0.1250],\n",
      "        [0.5484, 0.5700, 0.0469, 0.1000]]), 'area': tensor([180., 115.]), 'iscrowd': tensor([0, 0]), 'orig_size': tensor([200, 320])}\n",
      "torch.int64\n"
     ]
    }
   ],
   "source": [
    "pixel_values, labels = dataset[0]\n",
    "print(f\"Loaded pixel values shape: {pixel_values.shape}\")\n",
    "print(f\"Loaded labels: {labels}\")\n",
    "\n",
    "print(f\"{labels['class_labels'].dtype}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2a0c358f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken to fetch 1000 items: 0.90 seconds\n"
     ]
    }
   ],
   "source": [
    "# benchmarking dataset, which includes preprocessing\n",
    "import time\n",
    "\n",
    "start_time = time.perf_counter()\n",
    "for i in range(1000):\n",
    "    pixel_values, labels = dataset[i]\n",
    "end_time = time.perf_counter()\n",
    "elapsed_time = end_time - start_time\n",
    "print(f\"Time taken to fetch 1000 items: {elapsed_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8a130c8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken to fetch 1000 items: 0.95 seconds\n"
     ]
    }
   ],
   "source": [
    "# benchmarking disk-cached dataset\n",
    "import time\n",
    "from Vision.datasets import PreprocessedDataset\n",
    "\n",
    "cached_dataset = PreprocessedDataset(\n",
    "    dataset=dataset,\n",
    "    cache_dir=os.path.join(os.pardir, os.pardir, \"datasets\", \"cocodoom\", \"preprocessed\")\n",
    ")\n",
    "\n",
    "start_time = time.perf_counter()\n",
    "for i in range(1000):\n",
    "    pixel_values, labels = cached_dataset[i]\n",
    "end_time = time.perf_counter()\n",
    "elapsed_time = end_time - start_time\n",
    "print(f\"Time taken to fetch 1000 items: {elapsed_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee77d110",
   "metadata": {},
   "source": [
    "# Benchmarking Processors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6b4b8a33",
   "metadata": {},
   "outputs": [],
   "source": [
    "processor1 = DetrImageProcessor.from_pretrained(\"facebook/detr-resnet-50\")\n",
    "processor2 = DetrImageProcessor.from_pretrained(\"facebook/detr-resnet-50\", use_fast=True)\n",
    "processor3 = DetrImageProcessorFast.from_pretrained(\"facebook/detr-resnet-50\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ab4d8118",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processor 1 time taken to process 1000 items: 13.39 seconds\n",
      "Processor 2 time taken to process 1000 items: 13.39 seconds\n",
      "Processor 3 time taken to process 1000 items: 2.66 seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "start_time = time.perf_counter()\n",
    "for i in range(1000):\n",
    "    img, target, _ = dataset.get_image(i)\n",
    "    processor1(images=img, annotations=target, return_tensors=\"pt\")\n",
    "\n",
    "end_time = time.perf_counter()\n",
    "elapsed_time = end_time - start_time\n",
    "print(f\"Processor 1 time taken to process 1000 items: {elapsed_time:.2f} seconds\")\n",
    "\n",
    "start_time = time.perf_counter()\n",
    "for i in range(1000):\n",
    "    img, target, _ = dataset.get_image(i)\n",
    "    processor2(images=img, annotations=target, return_tensors=\"pt\")\n",
    "\n",
    "end_time = time.perf_counter()\n",
    "elapsed_time = end_time - start_time\n",
    "print(f\"Processor 2 time taken to process 1000 items: {elapsed_time:.2f} seconds\")\n",
    "\n",
    "start_time = time.perf_counter()\n",
    "for i in range(1000):\n",
    "    img, target, _ = dataset.get_image(i)\n",
    "    processor3(images=img, annotations=target, return_tensors=\"pt\")\n",
    "\n",
    "end_time = time.perf_counter()\n",
    "elapsed_time = end_time - start_time\n",
    "print(f\"Processor 3 time taken to process 1000 items: {elapsed_time:.2f} seconds\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0f05574",
   "metadata": {},
   "source": [
    "# Converting CocoDoom to YOLO Format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5d789b6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting run-train.json: 100%|██████████| 50732/50732 [00:01<00:00, 42100.81it/s]\n",
      "Converting run-val.json: 100%|██████████| 9510/9510 [00:00<00:00, 40736.04it/s]\n",
      "Converting run-test.json: 100%|██████████| 5907/5907 [00:00<00:00, 40833.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conversion complete!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "def convert_coco_to_yolo(coco_json_path, output_dir):\n",
    "    \"\"\"\n",
    "    Convert COCO format annotations to YOLO format.\n",
    "\n",
    "    This is necessary because the standard YOLO converter\n",
    "    does not work if the file paths contain subdirectories.\n",
    "    \n",
    "    Args:\n",
    "        coco_json_path: Path to COCO JSON file\n",
    "        output_dir: Root directory to save YOLO format labels\n",
    "    \"\"\"\n",
    "    # Load COCO JSON\n",
    "    with open(coco_json_path, 'r') as f:\n",
    "        coco_data = json.load(f)\n",
    "    \n",
    "    # Create mapping from image_id to annotations\n",
    "    img_annotations = {}\n",
    "    for ann in coco_data['annotations']:\n",
    "        img_id = ann['image_id']\n",
    "        if img_id not in img_annotations:\n",
    "            img_annotations[img_id] = []\n",
    "        img_annotations[img_id].append(ann)\n",
    "    \n",
    "    # Process each image\n",
    "    for image in tqdm(coco_data['images'], desc=f\"Converting {Path(coco_json_path).name}\"):\n",
    "        img_id = image['id']\n",
    "        img_width = image['width']\n",
    "        img_height = image['height']\n",
    "        file_name = image['file_name']\n",
    "        \n",
    "        # Create output label path based on image path structure\n",
    "        # labels/path/to/image.txt\n",
    "        label_file = Path(output_dir) / 'labels' / file_name\n",
    "        label_file = label_file.with_suffix('.txt')\n",
    "        \n",
    "        # Create parent directories if they don't exist\n",
    "        label_file.parent.mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "        # Get annotations for this image\n",
    "        annotations = img_annotations.get(img_id, [])\n",
    "        \n",
    "        # Write YOLO format labels\n",
    "        with open(label_file, 'w') as f:\n",
    "            for ann in annotations:\n",
    "                # COCO bbox format: [x, y, width, height] in image coordinates\n",
    "                bbox = ann['bbox']\n",
    "                x, y, w, h = bbox\n",
    "                \n",
    "                # Convert to YOLO format: [x_center, y_center, width, height] normalized\n",
    "                x_center = (x + w / 2) / img_width\n",
    "                y_center = (y + h / 2) / img_height\n",
    "                w_norm = w / img_width\n",
    "                h_norm = h / img_height\n",
    "                \n",
    "                # Clamp values to [0, 1]\n",
    "                x_center = max(0, min(1, x_center))\n",
    "                y_center = max(0, min(1, y_center))\n",
    "                w_norm = max(0, min(1, w_norm))\n",
    "                h_norm = max(0, min(1, h_norm))\n",
    "                \n",
    "                # Class ID from category_id\n",
    "                class_id = ann['category_id']\n",
    "                \n",
    "                # Write to file: class_id x_center y_center width height (all normalized)\n",
    "                f.write(f\"{class_id} {x_center:.6f} {y_center:.6f} {w_norm:.6f} {h_norm:.6f}\\n\")\n",
    "\n",
    "# Convert all splits\n",
    "coco_root = \"/home/xavier/projects/datasets/cocodoom\"\n",
    "output_root = \"/home/xavier/projects/datasets/cocodoom/yolo\"\n",
    "\n",
    "for split in ['run-train.json', 'run-val.json', 'run-test.json']:\n",
    "    coco_json_path = os.path.join(coco_root, split)\n",
    "    if os.path.exists(coco_json_path):\n",
    "        convert_coco_to_yolo(coco_json_path, output_root)\n",
    "    else:\n",
    "        print(f\"Skipping {split} - file not found\")\n",
    "\n",
    "print(\"Conversion complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "71da8ff1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "YOLO dataset organization complete!\n",
      "\n",
      "data.yaml created at /home/xavier/projects/datasets/cocodoom/yolo/data.yaml\n",
      "names:\n",
      "  0: POSSESSED\n",
      "  1: SHOTGUY\n",
      "  2: VILE\n",
      "  3: FIRE\n",
      "  4: UNDEAD\n",
      "  5: TRACER\n",
      "  6: SMOKE\n",
      "  7: FATSO\n",
      "  8: FATSHOT\n",
      "  9: CHAINGUY\n",
      "  10: TROOP\n",
      "  11: SERGEANT\n",
      "  12: HEAD\n",
      "  13: BRUISER\n",
      "  14: BRUISERSHOT\n",
      "  15: KNIGHT\n",
      "  16: SKULL\n",
      "  17: SPIDER\n",
      "  18: BABY\n",
      "  19: CYBORG\n",
      "  20: PAIN\n",
      "  21: WOLFSS\n",
      "  22: BARREL\n",
      "  23: TROOPSHOT\n",
      "  24: HEADSHOT\n",
      "  25: ROCKET\n",
      "  26: PLASMA\n",
      "  27: BFG\n",
      "  28: ARACHPLAZ\n",
      "  29: PUFF\n",
      "  30: BLOOD\n",
      "  31: TFOG\n",
      "  32: EXTRABFG\n",
      "  33: MISC0\n",
      "  34: MISC1\n",
      "  35: MISC2\n",
      "  36: MISC3\n",
      "  37: MISC4\n",
      "  38: MISC10\n",
      "  39: MISC11\n",
      "  40: MISC12\n",
      "  41: INV\n",
      "  42: MISC13\n",
      "  43: INS\n",
      "  44: MISC14\n",
      "  45: MISC15\n",
      "  46: MEGA\n",
      "  47: CLIP\n",
      "  48: MISC17\n",
      "  49: MISC18\n",
      "  50: MISC19\n",
      "  51: MISC20\n",
      "  52: MISC21\n",
      "  53: MISC22\n",
      "  54: MISC23\n",
      "  55: MISC24\n",
      "  56: MISC25\n",
      "  57: CHAINGUN\n",
      "  58: MISC26\n",
      "  59: MISC27\n",
      "  60: MISC28\n",
      "  61: SHOTGUN\n",
      "  62: SUPERSHOTGUN\n",
      "  63: MISC29\n",
      "  64: MISC30\n",
      "  65: MISC32\n",
      "  66: MISC33\n",
      "  67: MISC34\n",
      "  68: MISC38\n",
      "  69: MISC39\n",
      "  70: MISC40\n",
      "  71: MISC41\n",
      "  72: MISC42\n",
      "  73: MISC43\n",
      "  74: MISC44\n",
      "  75: MISC45\n",
      "  76: MISC46\n",
      "  77: MISC47\n",
      "  78: MISC49\n",
      "  79: MISC50\n",
      "  80: MISC56\n",
      "  81: MISC58\n",
      "  82: MISC59\n",
      "  83: MISC60\n",
      "  84: MISC67\n",
      "  85: MISC68\n",
      "  86: MISC69\n",
      "  87: MISC71\n",
      "  88: MISC73\n",
      "  89: MISC74\n",
      "  90: MISC75\n",
      "  91: MISC76\n",
      "  92: MISC77\n",
      "  93: MISC84\n",
      "path: /home/xavier/projects/datasets/cocodoom/yolo\n",
      "test: images/test\n",
      "train: images/train\n",
      "val: images/val\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import shutil\n",
    "from pathlib import Path\n",
    "import json\n",
    "import yaml\n",
    "\n",
    "def create_yaml_file(path, categories):\n",
    "    # construct names dictionary with sequential IDs\n",
    "    names = {i: cat['name'] for i, cat in enumerate(categories)}\n",
    "\n",
    "    yaml_content = {\n",
    "        'path': str(Path(path).absolute()),\n",
    "        'train': 'images/train',\n",
    "        'val': 'images/val',\n",
    "        'test': 'images/test',\n",
    "        'names': names\n",
    "    }\n",
    "\n",
    "    yaml_path = Path(path) / 'data.yaml'\n",
    "    with open(yaml_path, 'w') as f:\n",
    "        yaml.dump(yaml_content, f)\n",
    "    \n",
    "    print(f\"\\ndata.yaml created at {yaml_path}\")\n",
    "    print(yaml.dump(yaml_content))\n",
    "\n",
    "\n",
    "def organize_yolo_dataset(yolo_root, coco_root, coco_data):\n",
    "    \"\"\"\n",
    "    Organize YOLO dataset into flat structure expected by YOLO.\n",
    "    \n",
    "    Creates:\n",
    "    - images/train/, images/val/, images/test/\n",
    "    - labels/train/, labels/val/, labels/test/\n",
    "    - data.yaml\n",
    "    \n",
    "    Args:\n",
    "        yolo_root: Path to YOLO dataset root\n",
    "        coco_root: Path to original COCO dataset root\n",
    "    \"\"\"\n",
    "    yolo_path = Path(yolo_root)\n",
    "    coco_path = Path(coco_root)\n",
    "    \n",
    "    # Create directory structure\n",
    "    for split_name in ['train', 'val', 'test']:\n",
    "        (yolo_path / 'images' / split_name).mkdir(parents=True, exist_ok=True)\n",
    "        (yolo_path / 'labels' / split_name).mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    # Load COCO JSONs to get image file names\n",
    "    splits = {\n",
    "        'train': 'run-train.json',\n",
    "        'val': 'run-val.json',\n",
    "        'test': 'run-test.json'\n",
    "    }\n",
    "    \n",
    "    # Process each split\n",
    "    for split_name, json_file in splits.items():\n",
    "        json_path = coco_path / json_file\n",
    "        \n",
    "        if not json_path.exists():\n",
    "            print(f\"Skipping {split_name} - file not found\")\n",
    "            continue\n",
    "        \n",
    "        with open(json_path, 'r') as f:\n",
    "            coco_data = json.load(f)\n",
    "        \n",
    "        print(f\"\\nProcessing {split_name} split...\")\n",
    "        \n",
    "        # Copy images and labels\n",
    "        for image in tqdm(coco_data['images'], desc=f\"{split_name}\"):\n",
    "            file_name = image['file_name']\n",
    "            \n",
    "            # Find the original image file\n",
    "            # The file_name includes the run/map structure like \"run1/map01/rgb/image.png\"\n",
    "            src_img = coco_path / file_name\n",
    "            \n",
    "            if src_img.exists():\n",
    "                # Create a unique flat filename: run1_map01_rgb_image.png\n",
    "                flat_name = file_name.replace('/', '_')\n",
    "                dst_img = yolo_path / 'images' / split_name / flat_name\n",
    "\n",
    "                # skip if already exists\n",
    "                if dst_img.exists():\n",
    "                    continue\n",
    "                \n",
    "                # Copy image (use symlink for speed if on same filesystem)\n",
    "                try:\n",
    "                    os.symlink(src_img.absolute(), dst_img)\n",
    "                except (FileExistsError, OSError):\n",
    "                    # If symlink fails, copy the file\n",
    "                    if not dst_img.exists():\n",
    "                        shutil.copy2(src_img, dst_img)\n",
    "                \n",
    "                # Copy corresponding label\n",
    "                nested_label = yolo_path / 'labels' / file_name\n",
    "                nested_label = nested_label.with_suffix('.txt')\n",
    "                \n",
    "                if nested_label.exists():\n",
    "                    flat_label = yolo_path / 'labels' / split_name / flat_name\n",
    "                    flat_label = flat_label.with_suffix('.txt')\n",
    "                    \n",
    "                    if not flat_label.exists():\n",
    "                        shutil.copy2(nested_label, flat_label)\n",
    "            else:\n",
    "                print(f\"Warning: Image not found: {src_img}\")\n",
    "\n",
    "# Run the organization\n",
    "yolo_root = \"/home/xavier/projects/datasets/cocodoom/yolo\"\n",
    "coco_root = \"/home/xavier/projects/datasets/cocodoom\"\n",
    "\n",
    "with open(Path(coco_root) / 'run-train.json', 'r') as f:\n",
    "    coco_data = json.load(f)\n",
    "\n",
    "# organize_yolo_dataset(yolo_root, coco_root, coco_data)\n",
    "print(\"\\nYOLO dataset organization complete!\")\n",
    "\n",
    "# Generate data.yaml\n",
    "create_yaml_file(yolo_root, coco_data['categories'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "doom-venv (3.12.12)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
